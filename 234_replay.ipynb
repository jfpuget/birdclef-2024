{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74750cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "\n",
    "cfg = SimpleNamespace(**{})\n",
    "cfg.num_folds = 5\n",
    "cfg.fold = -1\n",
    "cfg.gpu = \"7\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = cfg.gpu\n",
    "\n",
    "cfg.fname = 'bird_003'\n",
    "cfg.seed = 2024\n",
    "\n",
    "cfg.input_path = Path('../input')\n",
    "cfg.comp_data_path = cfg.input_path / 'birdclef-2024'\n",
    "cfg.save_path = Path('../checkpoints')\n",
    "cfg.soundscape_path = cfg.comp_data_path / 'unlabeled_soundscapes'\n",
    "\n",
    "cfg.logger_file = True\n",
    "\n",
    "# image size\n",
    "cfg.image_height = 224\n",
    "cfg.image_width = 224\n",
    "\n",
    "# audio\n",
    "cfg.duration = 5\n",
    "cfg.sr = 32000\n",
    "cfg.fmin = 90\n",
    "cfg.fmax = 14000\n",
    "cfg.n_fft = 1536\n",
    "cfg.n_mels = cfg.image_height\n",
    "cfg.win_length = 1024\n",
    "cfg.hop_length = int((cfg.duration * cfg.sr - cfg.win_length + cfg.n_fft) / (cfg.image_width)) + 1 \n",
    "\n",
    "# training HP\n",
    "cfg.num_epochs = 30\n",
    "cfg.train_batch_size = 128\n",
    "cfg.valid_batch_size = 128\n",
    "cfg.workers = 2\n",
    "cfg.grad_value = 2.0\n",
    "cfg.grad_norm = 0.0\n",
    "cfg.grad_norm_type = 2\n",
    "cfg.device = \"cuda\"\n",
    "cfg.accumulate = 1\n",
    "\n",
    "# optimizer\n",
    "cfg.lr = 7e-5\n",
    "cfg.decay = 0.01\n",
    "cfg.opt_beta1 = 0.9\n",
    "cfg.opt_beta2 = 0.999\n",
    "cfg.opt_eps = 1e-8\n",
    "cfg.optimizer = 'AdamW'\n",
    "cfg.no_decay = True\n",
    "\n",
    "# scheduler\n",
    "cfg.pct_start = 0.1\n",
    "cfg.max_lr = 3e-3\n",
    "cfg.final_div_factor = 100\n",
    "\n",
    "# augmentations\n",
    "cfg.resample_train = 10\n",
    "cfg.other_samples = 1\n",
    "cfg.max_shift = 1\n",
    "cfg.loudness_range = 10.0\n",
    "\n",
    "# logging\n",
    "cfg.local_rank = 0\n",
    "cfg.verbose=True\n",
    "\n",
    "# model\n",
    "cfg.backbone = 'efficientvit_b0.r224_in1k'\n",
    "cfg.gem_pooling = False\n",
    "cfg.bce = True\n",
    "\n",
    "# tasks hp\n",
    "cfg.train_model = True\n",
    "cfg.num_folds = 5\n",
    "cfg.pl = None\n",
    "cfg.pretrained_path = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ba44d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "import gc\n",
    "import pickle as pkl\n",
    "\n",
    "import librosa\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "#import torch_audiomentations as tA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim import lr_scheduler, Adam, AdamW\n",
    "\n",
    "import timm\n",
    "\n",
    "from glob import glob\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.special import logit, expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8981b331",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "model_names = timm.list_models(pretrained=True)\n",
    "pprint(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5255c425",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.train_model:\n",
    "    checkpoint_path = cfg.save_path / cfg.fname\n",
    "    if not checkpoint_path.exists():\n",
    "        checkpoint_path.mkdir()\n",
    "    checkpoint_path = checkpoint_path / 'exp_0'\n",
    "    exp = 0\n",
    "    while(checkpoint_path.exists()):\n",
    "        exp += 1\n",
    "        checkpoint_path = cfg.save_path / cfg.fname / ('exp_%d' % exp)\n",
    "    checkpoint_path.mkdir()\n",
    "    cfg.checkpoint_path = checkpoint_path\n",
    "    print('saving checkpoints to', checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3ca9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger(cfg):\n",
    "    logger = getLogger(cfg.fname)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    if cfg.logger_file and cfg.train_model:\n",
    "        filename = cfg.checkpoint_path / 'run.log'\n",
    "        handler2 = FileHandler(filename=filename)\n",
    "        handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "        logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "def seed_torch(seed_value):\n",
    "    random.seed(seed_value) # Python\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "    if torch.backends.cudnn.is_available:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e102e3ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(cfg.comp_data_path / 'train_metadata.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7194230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['species'] = [filename.split('/')[0] for filename in train.filename]\n",
    "train['record'] = [filename.split('/')[1] for filename in train.filename]\n",
    "train['secondary_labels'] = [eval(sls) for sls in train['secondary_labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce4d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.groupby('record').size()\n",
    "df = df[df > 1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca82c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.groupby('record').agg({'species' : ['first', 'last'],\n",
    "                                  'secondary_labels': ['first', 'last'],\n",
    "                                 })\n",
    "df.columns = ['first_species', 'last_species', 'first_secondary', 'last_secondary']\n",
    "df = df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d788e47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(df[['record', 'first_species', 'last_species',]],\n",
    "                   how='left',\n",
    "                   on='record')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aed1086",
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = {\n",
    "    ('asbfly/XC724266.ogg', 'asbfly/XC724148.ogg'),\n",
    "    ('barswa/XC575749.ogg', 'barswa/XC575747.ogg'),\n",
    "    ('bcnher/XC669544.ogg', 'bcnher/XC669542.ogg'),\n",
    "    ('bkskit1/XC350251.ogg', 'bkskit1/XC350249.ogg'),\n",
    "    ('blhori1/XC417215.ogg', 'blhori1/XC417133.ogg'),\n",
    "    ('blhori1/XC743616.ogg', 'blhori1/XC537503.ogg'),\n",
    "    ('blrwar1/XC662286.ogg', 'blrwar1/XC662285.ogg'),\n",
    "    ('brakit1/XC743675.ogg', 'brakit1/XC537471.ogg'),\n",
    "    ('brcful1/XC197746.ogg', 'brcful1/XC157971.ogg'),\n",
    "    ('brnshr/XC510751.ogg', 'brnshr/XC510750.ogg'),\n",
    "    ('btbeat1/XC665307.ogg', 'btbeat1/XC513403.ogg'),\n",
    "    ('btbeat1/XC743618.ogg', 'btbeat1/XC683300.ogg'),\n",
    "    #('btbeat1/XC743619.ogg', 'btbeat1/XC683300.ogg'),\n",
    "    ('btbeat1/XC743618.ogg', 'btbeat1/XC743619.ogg'),\n",
    "    ('categr/XC787914.ogg', 'categr/XC438523.ogg'),\n",
    "    ('cohcuc1/XC253418.ogg', 'cohcuc1/XC241127.ogg'),\n",
    "    ('cohcuc1/XC423422.ogg', 'cohcuc1/XC423419.ogg'),\n",
    "    ('comgre/XC202776.ogg', 'comgre/XC192404.ogg'),\n",
    "    ('comgre/XC602468.ogg', 'comgre/XC175341.ogg'),\n",
    "    ('comgre/XC64628.ogg', 'comgre/XC58586.ogg'),\n",
    "    ('comior1/XC305930.ogg', 'comior1/XC303819.ogg'),\n",
    "    ('comkin1/XC207123.ogg', 'comior1/XC207062.ogg'),\n",
    "    ('comkin1/XC691421.ogg', 'comkin1/XC690633.ogg'),\n",
    "    ('commyn/XC577887.ogg', 'commyn/XC577886.ogg'),\n",
    "    ('commyn/XC652903.ogg', 'commyn/XC652901.ogg'),\n",
    "    ('compea/XC665320.ogg', 'compea/XC644022.ogg'),\n",
    "    ('comsan/XC385909.ogg', 'comsan/XC385908.ogg'),\n",
    "    ('comsan/XC643721.ogg', 'comsan/XC642698.ogg'),\n",
    "    ('comsan/XC667807.ogg', 'comsan/XC667806.ogg'),\n",
    "    ('comtai1/XC126749.ogg', 'comtai1/XC122978.ogg'),\n",
    "    ('comtai1/XC305210.ogg', 'comtai1/XC304811.ogg'),\n",
    "    ('comtai1/XC542375.ogg', 'comtai1/XC540351.ogg'),\n",
    "    ('comtai1/XC542379.ogg', 'comtai1/XC540352.ogg'),\n",
    "    ('crfbar1/XC615780.ogg', 'crfbar1/XC615778.ogg'),\n",
    "    ('dafbab1/XC188307.ogg', 'dafbab1/XC187059.ogg'),\n",
    "    ('dafbab1/XC188308.ogg', 'dafbab1/XC187068.ogg'),\n",
    "    ('dafbab1/XC188309.ogg', 'dafbab1/XC187069.ogg'),\n",
    "    ('dafbab1/XC197745.ogg', 'dafbab1/XC157972.ogg'),\n",
    "    ('eaywag1/XC527600.ogg', 'eaywag1/XC527598.ogg'),\n",
    "    ('eucdov/XC355153.ogg', 'eucdov/XC355152.ogg'),\n",
    "    ('eucdov/XC360303.ogg', 'eucdov/XC347428.ogg'),\n",
    "    ('eucdov/XC365606.ogg', 'eucdov/XC124694.ogg'),\n",
    "    ('eucdov/XC371039.ogg', 'eucdov/XC368596.ogg'),\n",
    "    ('eucdov/XC747422.ogg', 'eucdov/XC747408.ogg'),\n",
    "    ('eucdov/XC789608.ogg', 'eucdov/XC788267.ogg'),\n",
    "    ('goflea1/XC163901.ogg', 'bladro1/XC163901.ogg'),\n",
    "    ('goflea1/XC208794.ogg', 'bladro1/XC208794.ogg'),\n",
    "    ('goflea1/XC208795.ogg', 'bladro1/XC208795.ogg'),\n",
    "    ('goflea1/XC209203.ogg', 'bladro1/XC209203.ogg'),\n",
    "    ('goflea1/XC209549.ogg', 'bladro1/XC209549.ogg'),\n",
    "    ('goflea1/XC209564.ogg', 'bladro1/XC209564.ogg'),\n",
    "    ('graher1/XC357552.ogg', 'graher1/XC357551.ogg'),\n",
    "    ('graher1/XC590235.ogg', 'graher1/XC590144.ogg'),\n",
    "    ('grbeat1/XC304004.ogg', 'grbeat1/XC303999.ogg'),\n",
    "    ('grecou1/XC365426.ogg', 'grecou1/XC365425.ogg'),\n",
    "    ('greegr/XC247286.ogg', 'categr/XC197438.ogg'),\n",
    "    ('grewar3/XC743681.ogg', 'grewar3/XC537475.ogg'),\n",
    "    ('grnwar1/XC197744.ogg', 'grnwar1/XC157973.ogg'),\n",
    "    ('grtdro1/XC651708.ogg', 'grtdro1/XC613192.ogg'),\n",
    "    ('grywag/XC459760.ogg', 'grywag/XC457124.ogg'),\n",
    "    ('grywag/XC575903.ogg', 'grywag/XC575901.ogg'),\n",
    "    ('grywag/XC650696.ogg', 'grywag/XC592019.ogg'),\n",
    "    ('grywag/XC690448.ogg', 'grywag/XC655063.ogg'),\n",
    "    ('grywag/XC745653.ogg', 'grywag/XC745650.ogg'),\n",
    "    ('grywag/XC812496.ogg', 'grywag/XC812495.ogg'),\n",
    "    ('heswoo1/XC357155.ogg', 'heswoo1/XC357149.ogg'),\n",
    "    ('heswoo1/XC744698.ogg', 'heswoo1/XC665715.ogg'),\n",
    "    ('hoopoe/XC631301.ogg', 'hoopoe/XC365530.ogg'),\n",
    "    ('hoopoe/XC631304.ogg', 'hoopoe/XC252584.ogg'),\n",
    "    ('houcro1/XC744704.ogg', 'houcro1/XC683047.ogg'),\n",
    "    ('houspa/XC326675.ogg', 'houspa/XC326674.ogg'),\n",
    "    ('inbrob1/XC744708.ogg', 'inbrob1/XC744706.ogg'),\n",
    "    ('insowl1/XC305214.ogg', 'insowl1/XC301142.ogg'),\n",
    "    ('junbab2/XC282587.ogg', 'junbab2/XC282586.ogg'),\n",
    "    ('labcro1/XC267645.ogg', 'labcro1/XC265731.ogg'),\n",
    "    ('labcro1/XC345836.ogg', 'labcro1/XC312582.ogg'),\n",
    "    ('labcro1/XC37773.ogg', 'labcro1/XC19736.ogg'),\n",
    "    ('labcro1/XC447036.ogg', 'houcro1/XC447036.ogg'),\n",
    "    ('labcro1/XC823514.ogg', 'gybpri1/XC823527.ogg'),\n",
    "    ('laudov1/XC185511.ogg', 'grewar3/XC185505.ogg'),\n",
    "    ('laudov1/XC405375.ogg', 'laudov1/XC405374.ogg'),\n",
    "    ('laudov1/XC514027.ogg', 'eucdov/XC514027.ogg'),\n",
    "    ('lblwar1/XC197743.ogg', 'lblwar1/XC157974.ogg'),\n",
    "    ('lewduc1/XC261506.ogg', 'lewduc1/XC254813.ogg'),\n",
    "    ('litegr/XC403621.ogg', 'bcnher/XC403621.ogg'),\n",
    "    ('litegr/XC535540.ogg', 'litegr/XC448898.ogg'),\n",
    "    ('litegr/XC535552.ogg', 'litegr/XC447850.ogg'),\n",
    "    ('litgre1/XC630775.ogg', 'litgre1/XC630560.ogg'),\n",
    "    ('litgre1/XC776082.ogg', 'litgre1/XC663244.ogg'),\n",
    "    ('litspi1/XC674522.ogg', 'comtai1/XC674522.ogg'),\n",
    "    ('litspi1/XC722435.ogg', 'litspi1/XC721636.ogg'),\n",
    "    ('litspi1/XC722436.ogg', 'litspi1/XC721637.ogg'),\n",
    "    ('litswi1/XC443070.ogg', 'litswi1/XC440301.ogg'),\n",
    "    ('lobsun2/XC197742.ogg', 'lobsun2/XC157975.ogg'),\n",
    "    ('maghor2/XC197740.ogg', 'maghor2/XC157978.ogg'),\n",
    "    ('maghor2/XC786588.ogg', 'maghor2/XC786587.ogg'),\n",
    "    ('malpar1/XC197770.ogg', 'malpar1/XC157976.ogg'),\n",
    "    ('marsan/XC383290.ogg', 'marsan/XC383288.ogg'),\n",
    "    ('marsan/XC733175.ogg', 'marsan/XC716673.ogg'),\n",
    "    ('mawthr1/XC455222.ogg', 'mawthr1/XC455211.ogg'),\n",
    "    ('orihob2/XC557991.ogg', 'orihob2/XC557293.ogg'),\n",
    "    ('piebus1/XC165050.ogg', 'piebus1/XC122395.ogg'),\n",
    "    ('piebus1/XC814459.ogg', 'piebus1/XC792272.ogg'),\n",
    "    ('placuc3/XC490344.ogg', 'placuc3/XC486683.ogg'),\n",
    "    ('placuc3/XC572952.ogg', 'placuc3/XC572950.ogg'),\n",
    "    ('plaflo1/XC615781.ogg', 'plaflo1/XC614946.ogg'),\n",
    "    ('purher1/XC467373.ogg', 'graher1/XC467373.ogg'),\n",
    "    ('purher1/XC827209.ogg', 'purher1/XC827207.ogg'),\n",
    "    ('pursun3/XC268375.ogg', 'comtai1/XC241382.ogg'),\n",
    "    ('pursun4/XC514853.ogg', 'pursun4/XC514852.ogg'),\n",
    "    ('putbab1/XC574864.ogg', 'brcful1/XC574864.ogg'),\n",
    "    ('rewbul/XC306398.ogg', 'bkcbul1/XC306398.ogg'),\n",
    "    ('rewbul/XC713308.ogg', 'asbfly/XC713467.ogg'),\n",
    "    ('rewlap1/XC733007.ogg', 'rewlap1/XC732874.ogg'),\n",
    "    ('rorpar/XC199488.ogg', 'rorpar/XC199339.ogg'),\n",
    "    ('rorpar/XC402325.ogg', 'comior1/XC402326.ogg'),\n",
    "    ('rorpar/XC516404.ogg', 'rorpar/XC516402.ogg'),\n",
    "    ('sbeowl1/XC522123.ogg', 'brfowl1/XC522123.ogg'),\n",
    "    ('sohmyn1/XC744700.ogg', 'sohmyn1/XC743682.ogg'),\n",
    "    ('spepic1/XC804432.ogg', 'spepic1/XC804431.ogg'),\n",
    "    ('spodov/XC163930.ogg', 'bladro1/XC163901.ogg'),\n",
    "    ('spodov/XC163930.ogg', 'goflea1/XC163901.ogg'),\n",
    "    ('spoowl1/XC591485.ogg', 'spoowl1/XC591177.ogg'),\n",
    "    ('stbkin1/XC266782.ogg', 'stbkin1/XC266682.ogg'),\n",
    "    ('stbkin1/XC360661.ogg', 'stbkin1/XC199815.ogg'),\n",
    "    ('stbkin1/XC406140.ogg', 'stbkin1/XC406138.ogg'),\n",
    "    ('vefnut1/XC197738.ogg', 'vefnut1/XC157979.ogg'),\n",
    "    ('vefnut1/XC293526.ogg', 'vefnut1/XC289785.ogg'),\n",
    "    ('wemhar1/XC581045.ogg', 'comsan/XC581045.ogg'),\n",
    "    ('wemhar1/XC590355.ogg', 'wemhar1/XC590354.ogg'),\n",
    "    ('whbbul2/XC335671.ogg', 'whbbul2/XC335670.ogg'),\n",
    "    ('whbsho3/XC856465.ogg', 'whbsho3/XC856463.ogg'),\n",
    "    #('whbsho3/XC856468.ogg', 'whbsho3/XC856463.ogg'),\n",
    "    ('whbsho3/XC856465.ogg', 'whbsho3/XC856468.ogg'),\n",
    "    ('whbwat1/XC840073.ogg', 'whbwat1/XC840071.ogg'),\n",
    "    ('whbwoo2/XC239509.ogg', 'rufwoo2/XC239509.ogg'),\n",
    "    ('whcbar1/XC659329.ogg', 'insowl1/XC659329.ogg'),\n",
    "    ('whiter2/XC265271.ogg', 'whiter2/XC265267.ogg'),\n",
    "    ('whtkin2/XC197737.ogg', 'whtkin2/XC157981.ogg'),\n",
    "    ('whtkin2/XC430267.ogg', 'whtkin2/XC430256.ogg'),\n",
    "    ('whtkin2/XC503389.ogg', 'comior1/XC503389.ogg'),\n",
    "    ('whtkin2/XC540094.ogg', 'whtkin2/XC540087.ogg'),\n",
    "    ('woosan/XC184466.ogg', 'marsan/XC184466.ogg'),\n",
    "    ('woosan/XC545316.ogg', 'woosan/XC476064.ogg'),\n",
    "    ('woosan/XC587076.ogg', 'woosan/XC578599.ogg'),\n",
    "    ('woosan/XC742927.ogg', 'woosan/XC740798.ogg'),\n",
    "    ('woosan/XC825766.ogg', 'grnsan/XC825765.ogg'),\n",
    "    ('zitcis1/XC303866.ogg', 'zitcis1/XC302781.ogg'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f123b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_remove(r0, r1):\n",
    "    name0 = r0.split('/')[0]\n",
    "    name1 = r1.split('/')[0]\n",
    "    return name0 == name1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2154ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = [(r0,r1) for (r0,r1) in dups if to_remove(r0, r1)]\n",
    "len(dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ede4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = set(r1 for r0,r1 in dups)\n",
    "len(to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53657344",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[~train.filename.isin(to_remove)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6422ac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.groupby('record').first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aca0e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['record_name'] = [record.split('.')[0] for record in train.record]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47858f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21292ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train = pd.read_csv('../all_train.csv')\n",
    "all_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b903ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train.groupby(['primary_label', 'source']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedabf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8591678",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train[all_train.secondary_labels != '[]'].source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9303a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train['species'] = all_train['primary_label']\n",
    "all_train['first_species'] = all_train['primary_label']\n",
    "all_train['last_species'] = all_train['primary_label']\n",
    "all_train['filename'] = [ species + '/' + record + '.npy' for species, record in zip(all_train['primary_label'], all_train['record_name'])]\n",
    "all_train['secondary_labels'] = [eval(sls) for sls in all_train['secondary_labels']]\n",
    "all_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ea5fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(filename, first, istrain, cfg):\n",
    "    filepath = filename.split('/')[0]\n",
    "    fname = filename.split('/')[1].split('.')[0]\n",
    "    filepath = cfg.input_path / 'birdclef_data' / filepath \n",
    "    if istrain:\n",
    "        max_duration =  int((cfg.duration + cfg.max_shift) * cfg.sr)\n",
    "    else:\n",
    "        max_duration = cfg.duration * cfg.sr\n",
    "    if first:\n",
    "        filepath = filepath / f\"first10_{fname}.npy\"\n",
    "        audio = np.load(filepath)\n",
    "        audio = audio[:max_duration]\n",
    "    else:\n",
    "        filepath = filepath / f\"last10_{fname}.npy\"\n",
    "        audio = np.load(filepath)\n",
    "        audio = audio[-max_duration:]\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f79121",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_audio('asbfly/XC134896.ogg', True, True, cfg).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4525a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_audio('crseag1/XC88411.mp3', True, True, cfg).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef2f3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_audio('zitcis1/XC124995.npy', True, True, cfg).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bb1558",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(train.record_name) & set(all_train.record_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ea6f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, all_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693b2d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61182ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = []\n",
    "\n",
    "kf = KFold(n_splits=cfg.num_folds, shuffle=True, random_state=0)\n",
    "for species, df in train.groupby('primary_label'):\n",
    "    df = df.reset_index(drop=True)\n",
    "    df['fold'] = -1\n",
    "    for fold, (train_index, valid_index) in enumerate(kf.split(df, df.primary_label)):\n",
    "        df.loc[valid_index, \"fold\"] = int(fold)\n",
    "    new_train.append(df)\n",
    "new_train = pd.concat(new_train).reset_index(drop=True)    \n",
    "new_train.fold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a765da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.groupby(['species', 'fold']).size().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c0ff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e3f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9f3e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(preds, targets, cfg):\n",
    "    score = {}\n",
    "    for j,label in enumerate(cfg.labels):\n",
    "        score[label] = roc_auc_score(targets[:, j], preds[:, j])\n",
    "    score_avg = np.mean([v for k,v in score.items()])\n",
    "    return score_avg, score\n",
    "\n",
    "def metric_db(train, oofs, cfg):\n",
    "    score = {}\n",
    "    for j,label in enumerate(cfg.labels):\n",
    "        score[label] = roc_auc_score(train.primary_label == label, oofs[label])\n",
    "    score_avg = np.mean([v for k,v in score.items()])\n",
    "    return score_avg, score\n",
    "    \n",
    "def my_softmax(preds):\n",
    "    preds = preds - preds.max(1, keepdims=True)\n",
    "    preds = np.exp(preds.clip(-20, 0))\n",
    "    preds = preds / preds.sum(1, keepdims=True)\n",
    "    return preds\n",
    "\n",
    "def bce_with_mask(preds, targets, mask):\n",
    "    loss = nn.BCEWithLogitsLoss(reduction='none')(preds, targets)\n",
    "    loss = loss * mask\n",
    "    loss = loss.mean()\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bdd49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.device = torch.device('cuda')\n",
    "if cfg.bce:\n",
    "    #cfg.loss = nn.BCEWithLogitsLoss()\n",
    "    cfg.loss = bce_with_mask\n",
    "else:\n",
    "    cfg.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "cfg.labels = np.array(sorted(train.species.unique()))\n",
    "cfg.num_labels = len(cfg.labels)\n",
    "cfg.targets = {v : i for i,v in enumerate(cfg.labels)}\n",
    "\n",
    "cfg.logger = get_logger(cfg)\n",
    "seed_torch(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8605497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdDataset():\n",
    "    def __init__(self, train, istrain, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.istrain = istrain\n",
    "        self.filename = train.filename.values\n",
    "        #self.primary_label = train.primary_label.values\n",
    "        self.secondary_labels = train.secondary_labels.values\n",
    "        self.first_species = train.first_species.values\n",
    "        self.last_species = train.last_species.values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.filename)\n",
    "    \n",
    "    def get_audio(self, idx):\n",
    "        filename = self.filename[idx]\n",
    "        duration = self.cfg.sr * self.cfg.duration\n",
    "        if self.istrain:\n",
    "            first = np.random.rand() < 0.5\n",
    "            audio = load_audio(filename, first, True, self.cfg)\n",
    "            if len(audio) < duration:\n",
    "                pad_length = np.random.randint(0, duration - len(audio) + 1) \n",
    "                audio = np.pad(audio, \n",
    "                               ((pad_length, duration - len(audio) - pad_length),), \n",
    "                               mode='constant')\n",
    "            else:\n",
    "                start = np.random.randint(0, len(audio) - duration + 1)\n",
    "                audio = audio[start : start + duration]\n",
    "        else:\n",
    "            audio = load_audio(filename, True, False, self.cfg)\n",
    "            audio = audio[:duration]\n",
    "            if len(audio) < duration:\n",
    "                pad_length = (duration - len(audio)) // 2\n",
    "                audio = np.pad(audio, \n",
    "                               ((pad_length, duration - len(audio) - pad_length),), \n",
    "                               mode='constant')\n",
    "        return audio\n",
    "      \n",
    "    def __getitem__(self, idx):\n",
    "        audio = self.get_audio(idx)\n",
    "        targets = np.zeros(len(cfg.labels), dtype=np.float32)        \n",
    "        targets[self.cfg.targets[self.first_species[idx]]] = 1.0\n",
    "        targets[self.cfg.targets[self.last_species[idx]]] = 1.0\n",
    "        secondary_mask = np.ones(len(cfg.labels), dtype=np.float32)\n",
    "        secondary_labels = self.secondary_labels[idx]\n",
    "        if len(secondary_labels) > 0:\n",
    "            for label in secondary_labels:\n",
    "                if label in cfg.targets:\n",
    "                    secondary_mask[cfg.targets[label]] = 0\n",
    "        if self.istrain and self.cfg.other_samples:\n",
    "            num_samples = np.random.randint(0, self.cfg.other_samples + 1)\n",
    "            for _ in range(num_samples):\n",
    "                other_idx = np.random.randint(len(self.filename))\n",
    "                other_audio = self.get_audio(other_idx)\n",
    "                weight = 0.2 + 0.8 *  np.random.rand()\n",
    "                audio += weight * other_audio\n",
    "                targets[self.cfg.targets[self.first_species[other_idx]]] = 1.0\n",
    "                targets[self.cfg.targets[self.last_species[other_idx]]] = 1.0\n",
    "                secondary_labels = self.secondary_labels[other_idx]\n",
    "                if len(secondary_labels) > 0:\n",
    "                    for label in secondary_labels:\n",
    "                        if label in cfg.targets:\n",
    "                            secondary_mask[cfg.targets[label]] = 0\n",
    "        secondary_mask = np.maximum(secondary_mask, targets)        \n",
    "        out = {\n",
    "            'audio' : torch.from_numpy(audio),\n",
    "            'targets' : torch.from_numpy(targets),\n",
    "            'secondary_mask' : secondary_mask,\n",
    "        }\n",
    "        return out\n",
    "\n",
    "def batch_to_device(batch, device):\n",
    "    return {k:batch[k].to(device, non_blocking=True) for k in batch.keys() if k not in []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3050dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BirdDataset(train, True, cfg)\n",
    "elt = dataset[0]\n",
    "for k,v in elt.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b747cb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(dataset, istrain, cfg):\n",
    "    if istrain:\n",
    "        batch_size = cfg.train_batch_size\n",
    "    else:\n",
    "        batch_size = cfg.valid_batch_size\n",
    "    data_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=cfg.workers,\n",
    "        shuffle=istrain,\n",
    "        pin_memory=False,\n",
    "        #collate_fn=collate_pad,\n",
    "        drop_last = istrain,\n",
    "    )\n",
    "    return data_loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394943dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6, p_trainable=True):\n",
    "        super(GeM,self).__init__()\n",
    "        if p_trainable:\n",
    "            self.p = Parameter(torch.ones(1)*p)\n",
    "        else:\n",
    "            self.p = p\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)       \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n",
    "\n",
    "class BirdModel(nn.Module):\n",
    "    def __init__(self, cfg, pretrained: bool = True):\n",
    "        super(BirdModel, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.mel = T.MelSpectrogram(\n",
    "            sample_rate=cfg.sr, n_fft=cfg.n_fft, win_length=cfg.win_length, \n",
    "            hop_length= cfg.hop_length, f_min=cfg.fmin, f_max=cfg.fmax, \n",
    "            n_mels=cfg.n_mels, mel_scale='htk', power=2.0)\n",
    "        self.A2DB = T.AmplitudeToDB(stype=\"power\")\n",
    "        self.backbone = timm.create_model(\n",
    "            cfg.backbone,\n",
    "            pretrained=pretrained,\n",
    "            drop_rate = 0.1,\n",
    "            #drop_path_rate = 0.2,\n",
    "            num_classes=cfg.num_labels, \n",
    "            #global_pool=''\n",
    "        )\n",
    "        #if cfg.gem_pooling == \"gem\":\n",
    "        #    self.backbone.head.global_pool = GeM(p_trainable=args.p_trainable)\n",
    "         \n",
    "    def forward(self, input_dict):\n",
    "        x = input_dict['audio']\n",
    "        with autocast(enabled=False), torch.no_grad():\n",
    "            x = x / torch.std(x, 1, keepdim=True)\n",
    "            x = x.float()\n",
    "            x = self.mel(x)\n",
    "            x = self.A2DB(x)\n",
    "            x = (x - 40) / 80\n",
    "        with torch.no_grad():\n",
    "            x = x.unsqueeze(1)\n",
    "            pos = torch.linspace(0., 1., x.size(2)).to(x.device)\n",
    "            pos = pos.unsqueeze(0).unsqueeze(0).unsqueeze(-1)\n",
    "            pos = pos.expand(x.size(0), 1, x.size(2), x.size(3))\n",
    "            x = x.expand(-1, 2, -1, -1)\n",
    "            x = torch.cat([x, pos], 1)\n",
    "\n",
    "        x = self.backbone(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a899ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = get_data_loader(dataset, False, cfg)\n",
    "model = BirdModel(cfg)\n",
    "for batch in data_loader:\n",
    "    break\n",
    "out = model(batch)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafc25a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(loader, model, optimizer, scheduler, scaler, device, cfg):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    if cfg.verbose:\n",
    "        bar = tqdm(range(len(loader)))\n",
    "    else:\n",
    "        bar = range(len(loader))\n",
    "    load_iter = iter(loader)\n",
    "    loss_l = []\n",
    "    grad_norm_l = []\n",
    "    \n",
    "    accumulate = cfg.accumulate\n",
    "    \n",
    "    for i, batch in zip(bar, load_iter):\n",
    "        input_dict = batch_to_device(batch, device)\n",
    "        with autocast(enabled=True):\n",
    "            targets = input_dict['targets']\n",
    "            if cfg.loudness_range:\n",
    "                loudness = - np.log(cfg.loudness_range)\n",
    "                bs = targets.shape[0]\n",
    "                #weight = 0.1 ** (cfg.loundness_range *  np.random.rand() / 10)\n",
    "                weight = torch.rand(bs, 1).to(targets.device)\n",
    "                weight = torch.exp(weight * loudness)\n",
    "                audio = input_dict['audio']\n",
    "                audio = audio * weight\n",
    "                input_dict['audio'] = audio\n",
    "            preds = model(input_dict)\n",
    "            if cfg.bce:\n",
    "                secondary_mask = input_dict['secondary_mask']\n",
    "                loss = cfg.loss(preds, targets, secondary_mask).mean()\n",
    "            else:\n",
    "                loss = cfg.loss(preds, targets).mean()\n",
    "        loss_l.append(loss.detach().cpu().item())\n",
    "        scaler.scale(loss / cfg.accumulate).backward() \n",
    "        accumulate -= 1\n",
    "        if accumulate == 0:\n",
    "            if cfg.grad_value:\n",
    "                scaler.unscale_(optimizer)\n",
    "                nn.utils.clip_grad_value_(model.parameters(), cfg.grad_value)\n",
    "            if cfg.grad_norm:\n",
    "                scaler.unscale_(optimizer)\n",
    "                total_norm = nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_norm).item()\n",
    "                if np.isnan(total_norm):\n",
    "                    total_norm = cfg.grad_norm\n",
    "                else:\n",
    "                    total_norm = np.clip(total_norm, 0, cfg.grad_norm)\n",
    "                grad_norm_l.append(total_norm)\n",
    "            scaler.step(optimizer)     \n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            accumulate = cfg.accumulate\n",
    "            scheduler.step()  \n",
    "        del preds, targets, loss, input_dict\n",
    "        if cfg.verbose:\n",
    "            if cfg.grad_norm:\n",
    "                bar.set_description('loss: %.4f grad norm %.1f' % (np.mean(loss_l), np.mean(grad_norm_l),))\n",
    "            else:\n",
    "                bar.set_description('loss: %.4f ' % np.mean(loss_l))\n",
    "    optimizer.zero_grad()\n",
    "    del loss_l, bar\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f13d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_epoch(loader, model, device, cfg):\n",
    "    model.eval()\n",
    "    model.zero_grad()\n",
    "    if cfg.verbose:\n",
    "        bar = tqdm(range(len(loader)))\n",
    "    else:\n",
    "        bar = range(len(loader))\n",
    "    load_iter = iter(loader)\n",
    "    preds_l = []\n",
    "    targets_l = []\n",
    "    with torch.no_grad():\n",
    "        for i, batch in zip(bar, load_iter):      \n",
    "            input_dict = batch_to_device(batch, device)\n",
    "            with autocast(enabled=False):\n",
    "                preds = model(input_dict)                \n",
    "            preds_l.append(preds.detach().cpu())\n",
    "            del preds, input_dict\n",
    "            targets = batch['targets']\n",
    "            targets_l.append(targets)\n",
    "        preds = torch.cat(preds_l)\n",
    "        targets = torch.cat(targets_l)\n",
    "        return preds.numpy(), targets.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b192c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, cfg):\n",
    "    no_decay = [\"bias\", \"norm\"]\n",
    "    if cfg.no_decay:\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.named_parameters() \n",
    "                        if not any(nd in n for nd in no_decay)],\n",
    "             'weight_decay': cfg.decay},\n",
    "            {'params': [p for n, p in model.named_parameters() \n",
    "                        if any(nd in n for nd in no_decay)],\n",
    "             'weight_decay': 0.0},\n",
    "        ] \n",
    "    else:\n",
    "        optimizer_parameters = model.parameters()\n",
    "    optimizer = torch.optim.AdamW(optimizer_parameters, lr=cfg.lr)\n",
    "    return optimizer\n",
    "\n",
    "def get_scheduler(optimizer, train_data_loader, cfg):\n",
    "    scheduler = lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=cfg.max_lr,\n",
    "        epochs=cfg.num_epochs,\n",
    "        steps_per_epoch=len(train_data_loader),\n",
    "        pct_start=cfg.pct_start,\n",
    "        anneal_strategy=\"cos\",\n",
    "        final_div_factor=cfg.final_div_factor,\n",
    "    )\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda8ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, fold, seed, cfg):\n",
    "    checkpoint = {\n",
    "        'model' : model.state_dict(),\n",
    "        'fold' : fold,\n",
    "        'seed' : seed,\n",
    "        }\n",
    "    checkpoint_path = cfg.checkpoint_path\n",
    "    save_path = checkpoint_path / ('%s_%d_%d.pt' % (cfg.fname, fold, seed))\n",
    "    if cfg.local_rank == 0:\n",
    "        cfg.logger.info('saving %s ...' % save_path)\n",
    "    torch.save(checkpoint, save_path)\n",
    "    if cfg.local_rank == 0:\n",
    "        cfg.logger.info('done')\n",
    "\n",
    "def load_checkpoint(fold, seed, cfg):\n",
    "    if cfg.pretrained_path:\n",
    "        checkpoint_path = cfg.pretrained_path\n",
    "    else:\n",
    "        checkpoint_path = cfg.checkpoint_path\n",
    "    save_path = checkpoint_path / ('%s_%d_%d.pt' % (cfg.fname, fold, seed, ))\n",
    "    cfg.logger.info('loading %s ...' % save_path)\n",
    "    checkpoint = torch.load(save_path, map_location='cpu')\n",
    "    model = BirdModel(cfg, pretrained=False).to(cfg.device)\n",
    "    model.load_state_dict(checkpoint['model'], strict=True)\n",
    "    model.eval()\n",
    "    cfg.logger.info('done')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d02c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(train_fold, cfg):\n",
    "    new_train = []\n",
    "    for species, df in train.groupby('species'):\n",
    "        new_train.append(df)\n",
    "        if len(df) < cfg.resample_train:\n",
    "            df = df.sample(n=(cfg.resample_train - len(df)), replace=True, random_state=cfg.seed)\n",
    "            new_train.append(df)\n",
    "    new_train = pd.concat(new_train).reset_index(drop=True)  \n",
    "    return new_train  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846e1e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "oofs = pd.DataFrame(columns=cfg.labels, index=train.index, data = 0.0)\n",
    "oofs['filename'] = train.filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f72b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(cfg.num_folds):\n",
    "    if cfg.fold >= 0 and cfg.fold != fold:\n",
    "        continue\n",
    "    seed = cfg.seed + fold\n",
    "    seed_torch(seed)\n",
    "    if cfg.pl is not None:\n",
    "        pl_train = get_pl_train(cfg)\n",
    "    else:\n",
    "        pl_train = None\n",
    "        train_fold = train[train.fold != fold]\n",
    "    valid_dataset = BirdDataset(train[train.fold == fold], False, cfg)\n",
    "    valid_dataloader = get_data_loader(valid_dataset, istrain=False, cfg=cfg)\n",
    "    device = cfg.device\n",
    "    \n",
    "    if cfg.pretrained_path:\n",
    "        model = load_checkpoint(fold, seed, cfg)\n",
    "    else:\n",
    "        model = BirdModel(cfg, pretrained=True).to(device)\n",
    "    optimizer = get_optimizer(model, cfg)\n",
    "    scheduler = None\n",
    "    scaler = GradScaler()\n",
    "    result = None\n",
    "    for epoch in range(cfg.num_epochs):\n",
    "        if cfg.pl is not None:\n",
    "            train_fold = sample_pl(train, fold, pl_train)\n",
    "        if cfg.resample_train:\n",
    "            train_fold = resample(train_fold, cfg)\n",
    "        train_dataset = BirdDataset(train_fold, True, cfg)\n",
    "        train_dataloader = get_data_loader(train_dataset, istrain=True, cfg=cfg)\n",
    "\n",
    "        if scheduler is None:\n",
    "            scheduler = get_scheduler(optimizer, train_dataloader, cfg)\n",
    "        train_epoch(train_dataloader, model, optimizer, scheduler, scaler, device, cfg)\n",
    "        if valid_dataset is not None:\n",
    "            preds, targets = valid_epoch(valid_dataloader, model, device, cfg)\n",
    "            if cfg.bce:\n",
    "                preds = expit(preds) # model uses logits\n",
    "            else:\n",
    "                preds = my_softmax(preds) # model uses logits\n",
    "            result, _ = metric(preds, targets, cfg)\n",
    "            msg = f\"seed {cfg.seed} fold {fold} epoch {epoch} metric {result:.4f}\"\n",
    "            cfg.logger.info(msg)\n",
    "        else:\n",
    "            msg = f\"seed {cfg.seed} fold {fold} epoch {epoch}\"\n",
    "            cfg.logger.info(msg)\n",
    "    if cfg.local_rank == 0:\n",
    "        save_checkpoint(model, fold, seed, cfg)\n",
    "    del model, optimizer, scheduler, scaler, train_dataloader, \n",
    "    if valid_dataset is not None:\n",
    "        del valid_dataloader\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    scores.append(result)\n",
    "    \n",
    "    for j,c in enumerate(cfg.labels):\n",
    "        oofs.loc[train.fold == fold, c] = preds[:, j]\n",
    "oofs.to_csv(cfg.checkpoint_path / 'oofs.csv', index=False)\n",
    "\n",
    "np.mean(scores), metric_db(train, oofs, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407e2aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = metric_db(train, oofs, cfg)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f8781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe = train.groupby('primary_label').size()\n",
    "dfe.name = 'size'\n",
    "dfe = dfe.reset_index().sort_values('primary_label').reset_index(drop=True)\n",
    "dfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eac166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'label' : cfg.labels, \n",
    "                   'roc_auc' : [res[1][label] for label in cfg.labels],\n",
    "                   'size' : dfe['size'].values,\n",
    "                  })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5207fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.log(df['size']), df['roc_auc'], marker='+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d362726",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ca130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.groupby('primary_label').size()\n",
    "df = df / df.sum()\n",
    "df.name = 'avg'\n",
    "df = df.to_frame()\n",
    "df['oof'] = oofs[cfg.labels].mean(0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742feb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.avg, df.oof/df.avg, marker='+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab5437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoundScapeDataset():\n",
    "    def __init__(self, soundscape, istrain, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.istrain = istrain\n",
    "        self.soundscape = soundscape\n",
    "        self.duration = int(np.round(soundscape.shape[0] / cfg.sr))\n",
    "        self.starts = np.arange(0, self.duration, cfg.duration)\n",
    "        self.ends = self.starts + cfg.duration\n",
    "        self.starts = cfg.sr * self.starts\n",
    "        self.ends = cfg.sr * self.ends\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.starts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio = self.soundscape[self.starts[idx] : self.ends[idx]]\n",
    "        duration = self.cfg.sr * self.cfg.duration\n",
    "        if len(audio) < duration:\n",
    "            pad_length = (duration - len(audio)) // 2\n",
    "            audio = np.pad(audio, \n",
    "                           ((pad_length, duration - len(audio) - pad_length),), \n",
    "                           mode='constant')\n",
    "        out = {\n",
    "            'audio' : torch.from_numpy(audio),\n",
    "        }\n",
    "        return out\n",
    "\n",
    "def predict(loader, models, cfg):\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        model.zero_grad()\n",
    "    if cfg.verbose:\n",
    "        bar = tqdm(range(len(loader)))\n",
    "    else:\n",
    "        bar = range(len(loader))\n",
    "    load_iter = iter(loader)\n",
    "    preds_l = [[] for model in models]\n",
    "    targets_l = []\n",
    "    with torch.no_grad():\n",
    "        for i, batch in zip(bar, load_iter):      \n",
    "            input_dict = batch_to_device(batch, cfg.device)\n",
    "            with autocast(enabled=False):\n",
    "                for preds, model in zip(preds_l, models):\n",
    "                    preds.append(model(input_dict).detach().cpu()) \n",
    "            del input_dict\n",
    "        preds_l = [torch.cat(preds).squeeze().numpy() for preds in preds_l]\n",
    "        return preds_l\n",
    "\n",
    "def load_soundscape(pathname, cfg):\n",
    "    #audio = librosa.load(pathname, sr=32000)[0].astype(np.float32)\n",
    "    filename = pathname.split('/')[-1].split('.')[0]\n",
    "    audio = np.load(cfg.input_path / 'birdclef_data' / 'unlabeled_soundscapes' / (filename + '.npy'))\n",
    "\n",
    "    return audio\n",
    "\n",
    "def predict_soundscape(filepath, models, cfg):\n",
    "    waveform = load_soundscape(filepath, cfg)\n",
    "    #return len(waveform) / cfg.sr\n",
    "    #return waveform\n",
    "    #print('duration',  len(waveform) / cfg.sr)\n",
    "    dataset = SoundScapeDataset(waveform, False, cfg)\n",
    "    dataloader = get_data_loader(dataset, False, cfg)\n",
    "    preds_l = predict(dataloader, models, cfg)\n",
    "    if cfg.bce:\n",
    "        preds_l = [expit(preds) for preds in preds_l] # model uses logits\n",
    "    else:\n",
    "        preds_l = [my_softmax(preds) for preds in preds_l] # model uses logits\n",
    "    return preds_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e808968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soundscapes = sorted(glob(str(cfg.soundscape_path / '*.ogg')))\n",
    "soundscapes[:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5397f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(cfg.checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d0d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp ../checkpoints/bird_003/exp_79?/*.pt ../checkpoints/bird_003/exp_790"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a1561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls  ../checkpoints/bird_003/exp_790"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed01148",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cfg.verbose = False\n",
    "cfg.workers = 0\n",
    "cfg.valid_batch_size = 128\n",
    "\n",
    "models = [load_checkpoint(fold, cfg.seed + fold, cfg).to(cfg.device)\n",
    "          for fold in range(cfg.num_folds)\n",
    "         ]\n",
    "preds = {}\n",
    "for soundscape in tqdm(soundscapes):\n",
    "    preds[soundscape]  = predict_soundscape(soundscape, models, cfg)\n",
    "with open(cfg.checkpoint_path / f\"pl_all.pkl\", \"wb\") as file:\n",
    "    pkl.dump(preds, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f0c356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
